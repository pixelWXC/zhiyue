产品名称： 智阅 --懂你的日语学习助手
平台： 浏览器插件
大模型服务 ：使用genai sdk，提供配置页面填写apikey，只在本地保存无后台服务器上传，gemini-3-flash-preview（结构分析、一句话问答）、gemini3 pro low （语法树分析）、nano banana pro （绘画）、gemini3 pro high （anki制卡），大模型提示词在配置页面配置（需要注意提醒用户需要json输出的提示词修改错误可能导致功能无法使用）。

核心功能：
绑定快捷键：在用户浏览网页的时候，获取用户剪切板文本、用户剪切板图片，通过指定快捷键呼出面板，默认Alt + U，可以配置。
日语句子结构分析：将用户文本传给大模型，分析日语句子结构，识别词汇、词性和语法成分、语音标注，流式输出整个句子的结构，可视化显示到面板。 
词汇详解：句子结构显示完全后，点击任意词汇查看详细释义、读音、词性和用法说明（接入在线词典）
一句话问答：分析结果顶部提供一个输入框，用户可以问：“为什么用 〜ている？”类似的问题并从llm处得到答案。
日语句子语法树分析：将用户文本传给大模型，分析日语句子语法，将其拆解为主语、谓语、修饰语和核心语法结构。语法树分析默认折叠，语法树分析结束后，提醒用户可以点击展开句子的语法树分析（可以在配置面板设置是否默认自动进行语法树分析、语法树分析获取结果后是否折叠）
单词/语法记忆卡片生成：将用户文本传给大模型，根据本次传入的文本，生成一张记忆卡片，点击下载按钮保存图片，保存图片页面还提供ai anki制卡，一键导出Anki（生成一个只含 1 行的tsv）的功能。


1. 技术架构
前端框架： Vue 3 + Vite。

UI 组件库： Shadcn-vue 或 Element Plus (轻量化定制)。

浏览器适配： CRXJS (用于构建现代插件)，Manifest V3。

AI 交互： Google GenAI SDK (运行在 Service Worker 或 Sidepanel 中)。

状态管理： Pinia (用于在 Content Script, Popup, Sidepanel 之间同步配置和历史记录)。

2. 交互流程设计
使用浏览器 Sidepanel

场景：用户按下 Alt + U

Step 1: 嗅探与决策 (Background Script)

读取 navigator.clipboard。

Case A (纯文本): 侧边栏打开 -> 显示“正在分析…” -> 调用 Flash 模型。

Case B (纯图片): 侧边栏打开 -> 显示截图缩略图 + “OCR中…” -> 调用 Flash (Vision 能力) 提取文本 -> 自动进入 Case A 流程。

Case C (混合/失败): 侧边栏打开 -> 顶部显示两个大按钮 [分析复制的文本] [分析截图] -> 用户点击后执行。

Step 2: 结构化分析 (Streaming)

UI 展示为一个分词容器。

随着 LLM Token 的流式返回，前端实时渲染 <span class="word" data-pos="动词">食べる</span>。

容错设计： 如果流式输出 JSON 损坏，尝试使用 json-repair 库进行修复，或者等到流结束再统一解析。

3. 核心功能模块详细设计
A. 日语句子结构分析 (Gemini 3 Flash)
Prompt 策略： 强制要求 JSON Schema。

数据结构：

JSON

{
  "original": "猫がベッドで寝ている",
  "tokens": [
    {"text": "猫", "reading": "ねこ", "pos": "名词", "grammar": "主语", "translation": "猫"},
    {"text": "が", "reading": "", "pos": "助词", "grammar": "主格标记", "translation": ""},
    {"text": "ベッド", "reading": "べっど", "pos": "名词", "grammar": "地点", "translation": "床"},
    {"text": "で", "reading": "", "pos": "助词", "grammar": "动作场所", "translation": "在"},
    {"text": "寝て", "reading": "ねて", "pos": "动词活用", "grammar": "te形", "translation": "睡"},
    {"text": "いる", "reading": "", "pos": "辅助动词", "grammar": "进行时", "translation": "正在"}
  ],
  "overall_meaning": "猫正在床上睡觉。"
}
UI 实现：

上方展示原文（带标注）。

点击单词，下方（或浮层）显示：[读音] [词性] [释义] + [外部链接: Jisho.org / Weblio]。

B. 语法树分析 (Gemini Pro Preview)
触发方式： 默认折叠，分析完成后显示“语法树已就绪 [展开]”。

让 LLM 输出嵌套 JSON 结构。

前端使用缩进式列表渲染。

Prompt 示例: "Analyze the syntax tree using dependency grammar. Output in nested JSON format."

C. 单词/语法记忆卡片 & Anki (Gemini Pro Preview + nano banana pro)
这是产品的“高光时刻” (Wow Moment)。

流程：

用户在分析结果中点击“生成卡片”。

Gemini Pro Preview 提取核心单词/语法，生成例句 (Front/Back/Hint)。

Nano Banana Pro 根据例句生成场景图 (Prompt: "A minimal, flat style illustration of a cat sleeping on a bed").

Anki 导出 (TSV):

格式：Question \t Answer \t ImageHTML \t Tags

允许用户直接复制这段文本，或者下载 .tsv 文件。

D. 配置页面 (Settings)
API Key 管理： 输入框 (type="password")，保存到 chrome.storage.local。

Prompt 自定义区 (高级)：

⚠️ 警告提示： “修改提示词可能导致解析失败，请确保保留 {json_schema} 占位符。”

提供“恢复默认”按钮。

快捷键绑定： 调用 chrome.commands API 进行展示和引导修改。

第三部分：Prompt Engineering 策略建议
为了保证 “用户自定义 Prompt” 和 “程序稳定性” 的平衡，建议采用 Template Injection 模式。

后端实际发送给 LLM 的 Prompt 结构：

Plaintext

[System]
你是一个专业的日语语言学专家。

[User Configurable Part]
(用户在这里写：请用幽默的语气解释，或者请使用简体中文...)

[Hardcoded Part - Do Not Edit]
必须严格遵守以下 JSON 格式输出，不要包含 Markdown 代码块标记：
{
  "tokens": [...]
}
待分析文本：{{user_clipboard_text}}
配置页面的设计： 只暴露 [User Configurable Part] 给用户。如果用户非要改 JSON 结构，需要开启一个“开发者模式”开关，并签署“风险自负”的弹窗。


大模型调用示例(均使用preview模型)：
import { GoogleGenAI } from "@google/genai";
import * as fs from "node:fs";

// 非流式输出（ocr）
  const response = await ai.models.generateContent({
    model: "gemini-3-flash-preview",
    contents: "Explain how AI works in a few words",
  });
  // 流式输出（语法树）
const response = await ai.models.generateContentStream({
          model: "gemini-3-pro-preview",
          contents: "Analyze the syntax tree using dependency grammar. Output in nested JSON format.",
          config: {
            thinkingConfig: {
              thinkingLevel: "low", // 分析使用"low"、"high"
            }
          }
        });
        for await (const chunk of response) {
    console.log(chunk.text);
  }

// 常规调用（图片生成）
const response = await ai.models.generateContent({
  model: "gemini-3-pro-image-preview",
  contents: "Create a picture of a futuristic banana with neon lights in a cyberpunk city.",
});

for (const part of response.candidates[0].content.parts) {
  if (part.inlineData) {
    const buffer = Buffer.from(part.inlineData.data, "base64");
    fs.writeFileSync("banana.png", buffer);
  }
}